{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr0yYhMALi6T"
      },
      "source": [
        "**Загрузка и подготовка данных**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FHtFKIYVQVTH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DF = pd.read_csv('/content/hotel_balanced.csv',encoding='utf-8',lineterminator='\\n')[['text','label']]\n",
        "DF1 = pd.read_csv('/content/phone_balanced.csv',encoding='utf-8',lineterminator='\\n')[['text','label']]\n",
        "DF2 = pd.read_csv('/content/reviews_balanced.csv',encoding='utf-8',lineterminator='\\n')[['text','label']]\n",
        "DF3 = pd.read_csv('/content/women_balanced.csv',encoding='utf-8',lineterminator='\\n')[['text','label']]\n",
        "\n",
        "lenth = min(len(DF),len(DF1),len(DF2),len(DF3))\n",
        "DF = DF.iloc[:lenth]\n",
        "DF1 = DF1.iloc[:lenth]\n",
        "DF2 = DF2.iloc[:lenth]\n",
        "DF3 = DF3.iloc[:lenth]\n",
        "\n",
        "hotel_data = DF.drop_duplicates()\n",
        "hotel_data = DF.dropna()\n",
        "\n",
        "phone_data = DF1.drop_duplicates()\n",
        "phone_data = DF1.dropna()\n",
        "\n",
        "reviews_data = DF2.drop_duplicates()\n",
        "reviews_data = DF2.dropna()\n",
        "\n",
        "women_data = DF3.drop_duplicates()\n",
        "women_data = DF3.dropna()"
      ],
      "metadata": {
        "id": "wIRhSb9Z143z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text_hotel, test_text_hotel, train_labels_hotel, test_labels_hotel = train_test_split(hotel_data[['text']], hotel_data[['label']], test_size=0.2, random_state=42)\n",
        "train_text_hotel, val_text_hotel, train_labels_hotel, val_labels_hotel = train_test_split(train_text_hotel, train_labels_hotel, test_size=0.25, random_state=42)\n",
        "\n",
        "train_text_phone, test_text_phone, train_labels_phone, test_labels_phone = train_test_split(phone_data[['text']], phone_data[['label']], test_size=0.2, random_state=42)\n",
        "train_text_phone, val_text_phone, train_labels_phone, val_labels_phone = train_test_split(train_text_phone, train_labels_phone, test_size=0.25, random_state=42)\n",
        "\n",
        "train_text_reviews, test_text_reviews, train_labels_reviews, test_labels_reviews = train_test_split(reviews_data[['text']], reviews_data[['label']], test_size=0.2, random_state=42)\n",
        "train_text_reviews, val_text_reviews, train_labels_reviews, val_labels_reviews = train_test_split(train_text_reviews, train_labels_reviews, test_size=0.25, random_state=42)\n",
        "\n",
        "train_text_women, test_text_women, train_labels_women, test_labels_women = train_test_split(women_data[['text']], women_data[['label']], test_size=0.2, random_state=42)\n",
        "train_text_women, val_text_women, train_labels_women, val_labels_women = train_test_split(train_text_women, train_labels_women, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "EA--ZoVj1Wf6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_train_data_text = pd.concat([train_text_hotel,train_text_phone,train_text_reviews,train_text_women], ignore_index=True)\n",
        "main_train_data_labels = pd.concat([train_labels_hotel,train_labels_phone,train_labels_reviews,train_labels_women], ignore_index=True)\n",
        "\n",
        "main_val_data_text = pd.concat([val_text_hotel,val_text_phone,val_text_reviews,val_text_women])\n",
        "main_val_data_labels = pd.concat([val_labels_hotel,val_labels_phone,val_labels_reviews,val_labels_women])\n",
        "\n",
        "main_test_data_text = pd.concat([test_text_hotel,test_text_phone,test_text_reviews,test_text_women])\n",
        "main_test_data_labels = pd.concat([test_labels_hotel,test_labels_phone,test_labels_reviews,test_labels_women])"
      ],
      "metadata": {
        "id": "QU072A5F5s7w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_train_data = main_train_data_text\n",
        "main_train_data['label'] = main_train_data_labels\n",
        "main_train_data = main_train_data.sample(frac=1).reset_index(drop=True)\n",
        "main_train_data.to_csv('main_train_data.csv')\n",
        "\n",
        "main_val_data = main_val_data_text\n",
        "main_val_data['label'] = main_val_data_labels\n",
        "main_val_data = main_val_data.sample(frac=1).reset_index(drop=True)\n",
        "main_val_data.to_csv('main_val_data.csv')\n",
        "\n",
        "main_test_data = main_test_data_text\n",
        "main_test_data['label'] = main_test_data_labels\n",
        "main_test_data = main_test_data.sample(frac=1).reset_index(drop=True)\n",
        "main_test_data.to_csv('main_test_data.csv')"
      ],
      "metadata": {
        "id": "2GNsWjXq9Oc9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_train_data = pd.read_csv('/content/drive/MyDrive/balanced_data/main_train_data.csv',encoding='utf-8',lineterminator='\\n')[['text','label']]\n",
        "main_val_data = pd.read_csv('/content/drive/MyDrive/balanced_data/main_val_data.csv',encoding='utf-8',lineterminator='\\n')[['text','label']]\n",
        "main_test_data = pd.read_csv('/content/reviews_balanced.csv',encoding='utf-8',lineterminator='\\n')[['text','label']]"
      ],
      "metadata": {
        "id": "9oZjmtVGDJ24"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KYY_7nOMGKf"
      },
      "source": [
        "**Подключение библиотек**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hhghEw_aQzY9"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "import torch\n",
        "from transformers import BertTokenizer, AutoTokenizer, AutoModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MbXmHjzL0N7"
      },
      "source": [
        "**Загрузка токенизатора с модели Twitter/twhin-bert-base**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "X5_NLK9rRCxS"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('Twitter/twhin-bert-base')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twcg2AmWMXMn"
      },
      "source": [
        "**График длин отзывов**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "yhyTJmvRaaUx",
        "outputId": "82451d58-dade-48ee-ac30-79c0906c8509"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fec6f0e1f40>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "seq_len = [len(str(i).split()) for i in main_train_data['text']]\n",
        "pd.Series(seq_len).hist(bins = 50)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_text = main_train_data['text'].astype('str')\n",
        "train_labels = main_train_data['label'].astype('int')\n",
        "val_text = main_val_data['text'].astype('str')\n",
        "val_labels = main_val_data['label'].astype('int')\n",
        "test_text = main_test_data['text'].astype('str')\n",
        "test_labels = main_test_data['label'].astype('int')"
      ],
      "metadata": {
        "id": "JsgM4mTlGYYP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcQNFmzFMzlU"
      },
      "source": [
        "**Токенизация данных**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Sjck_TJ1RN0j"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    list(train_text.values),\n",
        "    max_length = 240,\n",
        "    padding = 'max_length',\n",
        "    truncation = True\n",
        ")\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    list(val_text.values),\n",
        "    max_length = 240,\n",
        "    padding = 'max_length',\n",
        "    truncation = True\n",
        ")\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    list(test_text.values),\n",
        "    max_length = 240,\n",
        "    padding = 'max_length',\n",
        "    truncation = True\n",
        ")\n",
        "\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.values)\n",
        "\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.values)\n",
        "\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.values)\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\n",
        "\n",
        "val_data =  TensorDataset(val_seq, val_mask, val_y)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size = batch_size)\n",
        "\n",
        "test_data = TensorDataset(test_seq, test_mask)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9rzUHJxtuiO"
      },
      "source": [
        "**Загружаем модель Twitter/twhin-bert-base, добавляем 3 выхода**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6X-ErgV9Ry1u",
        "outputId": "f8629281-9f5a-4b00-964b-747bb75463cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at Twitter/twhin-bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at Twitter/twhin-bert-base and are newly initialized: ['classifier.weight', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"Twitter/twhin-bert-base\", \n",
        "                                                      num_labels = 3, \n",
        "                                                      output_attentions = False,\n",
        "                                                      output_hidden_states = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mc9k0R_WSQrA",
        "outputId": "ec0b85ca-7de1-43df-86f8-188105e8c3ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UjxDtmhYSTJe"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "n_epochs = 4\n",
        "\n",
        "n_steps = len(train_dataloader) * n_epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = n_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nSntJtFNpFZ"
      },
      "source": [
        "**Дообучение модели на датасете**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_P1CmtLSfWX",
        "outputId": "061ab2ee-0d10-464c-a278-9e5506ae0fb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Batch   100  of  1,570.    Time: 0:02:12.\n",
            "Batch   200  of  1,570.    Time: 0:04:33.\n",
            "Batch   300  of  1,570.    Time: 0:06:55.\n",
            "Batch   400  of  1,570.    Time: 0:09:19.\n",
            "Batch   500  of  1,570.    Time: 0:11:43.\n",
            "Batch   600  of  1,570.    Time: 0:14:07.\n",
            "Batch   700  of  1,570.    Time: 0:16:31.\n",
            "Batch   800  of  1,570.    Time: 0:18:55.\n",
            "Batch   900  of  1,570.    Time: 0:21:19.\n",
            "Batch 1,000  of  1,570.    Time: 0:23:43.\n",
            "Batch 1,100  of  1,570.    Time: 0:26:07.\n",
            "Batch 1,200  of  1,570.    Time: 0:28:31.\n",
            "Batch 1,300  of  1,570.    Time: 0:30:55.\n",
            "Batch 1,400  of  1,570.    Time: 0:33:19.\n",
            "Batch 1,500  of  1,570.    Time: 0:35:43.\n",
            "Mean loss:  0.0005728944481773934\n",
            "Training epoch took: 0:37:25\n",
            "\n",
            "Validation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.68      0.61      5607\n",
            "           1       0.82      0.62      0.70      5625\n",
            "           2       0.76      0.77      0.77      5512\n",
            "\n",
            "    accuracy                           0.69     16744\n",
            "   macro avg       0.71      0.69      0.69     16744\n",
            "weighted avg       0.71      0.69      0.69     16744\n",
            "\n",
            "Validation took: 0:04:11\n",
            "\n",
            "Training:\n",
            "Batch   100  of  1,570.    Time: 0:02:22.\n",
            "Batch   200  of  1,570.    Time: 0:04:46.\n",
            "Batch   300  of  1,570.    Time: 0:07:10.\n",
            "Batch   400  of  1,570.    Time: 0:09:34.\n",
            "Batch   500  of  1,570.    Time: 0:11:58.\n",
            "Batch   600  of  1,570.    Time: 0:14:22.\n",
            "Batch   700  of  1,570.    Time: 0:16:46.\n",
            "Batch   800  of  1,570.    Time: 0:19:10.\n",
            "Batch   900  of  1,570.    Time: 0:21:34.\n",
            "Batch 1,000  of  1,570.    Time: 0:23:58.\n",
            "Batch 1,100  of  1,570.    Time: 0:26:22.\n",
            "Batch 1,200  of  1,570.    Time: 0:28:46.\n",
            "Batch 1,300  of  1,570.    Time: 0:31:10.\n",
            "Batch 1,400  of  1,570.    Time: 0:33:34.\n",
            "Batch 1,500  of  1,570.    Time: 0:35:58.\n",
            "Mean loss:  0.0005064426506019203\n",
            "Training epoch took: 0:37:40\n",
            "\n",
            "Validation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.54      0.57      5607\n",
            "           1       0.74      0.80      0.77      5625\n",
            "           2       0.76      0.79      0.78      5512\n",
            "\n",
            "    accuracy                           0.71     16744\n",
            "   macro avg       0.71      0.71      0.71     16744\n",
            "weighted avg       0.71      0.71      0.71     16744\n",
            "\n",
            "Validation took: 0:04:11\n",
            "\n",
            "Training:\n",
            "Batch   100  of  1,570.    Time: 0:02:22.\n",
            "Batch   200  of  1,570.    Time: 0:04:47.\n",
            "Batch   300  of  1,570.    Time: 0:07:11.\n",
            "Batch   400  of  1,570.    Time: 0:09:36.\n",
            "Batch   500  of  1,570.    Time: 0:12:00.\n",
            "Batch   600  of  1,570.    Time: 0:14:25.\n",
            "Batch   700  of  1,570.    Time: 0:16:49.\n",
            "Batch   800  of  1,570.    Time: 0:19:14.\n",
            "Batch   900  of  1,570.    Time: 0:21:39.\n",
            "Batch 1,000  of  1,570.    Time: 0:24:03.\n",
            "Batch 1,100  of  1,570.    Time: 0:26:27.\n",
            "Batch 1,200  of  1,570.    Time: 0:28:52.\n",
            "Batch 1,300  of  1,570.    Time: 0:31:16.\n",
            "Batch 1,400  of  1,570.    Time: 0:33:41.\n",
            "Batch 1,500  of  1,570.    Time: 0:36:05.\n",
            "Mean loss:  0.00034381123533101034\n",
            "Training epoch took: 0:37:47\n",
            "\n",
            "Validation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.54      0.58      5607\n",
            "           1       0.73      0.83      0.77      5625\n",
            "           2       0.78      0.78      0.78      5512\n",
            "\n",
            "    accuracy                           0.71     16744\n",
            "   macro avg       0.71      0.71      0.71     16744\n",
            "weighted avg       0.71      0.71      0.71     16744\n",
            "\n",
            "Validation took: 0:04:12\n",
            "\n",
            "Training:\n",
            "Batch   100  of  1,570.    Time: 0:02:22.\n",
            "Batch   200  of  1,570.    Time: 0:04:47.\n",
            "Batch   300  of  1,570.    Time: 0:07:11.\n",
            "Batch   400  of  1,570.    Time: 0:09:36.\n",
            "Batch   500  of  1,570.    Time: 0:12:00.\n",
            "Batch   600  of  1,570.    Time: 0:14:24.\n",
            "Batch   700  of  1,570.    Time: 0:16:49.\n",
            "Batch   800  of  1,570.    Time: 0:19:14.\n",
            "Batch   900  of  1,570.    Time: 0:21:38.\n",
            "Batch 1,000  of  1,570.    Time: 0:24:02.\n",
            "Batch 1,100  of  1,570.    Time: 0:26:27.\n",
            "Batch 1,200  of  1,570.    Time: 0:28:51.\n",
            "Batch 1,300  of  1,570.    Time: 0:31:16.\n",
            "Batch 1,400  of  1,570.    Time: 0:33:40.\n",
            "Batch 1,500  of  1,570.    Time: 0:36:05.\n",
            "Mean loss:  0.00022620070847048185\n",
            "Training epoch took: 0:37:47\n",
            "\n",
            "Validation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.61      0.61      5607\n",
            "           1       0.76      0.77      0.77      5625\n",
            "           2       0.78      0.77      0.77      5512\n",
            "\n",
            "    accuracy                           0.71     16744\n",
            "   macro avg       0.72      0.71      0.72     16744\n",
            "weighted avg       0.72      0.71      0.72     16744\n",
            "\n",
            "Validation took: 0:04:12\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from datetime import timedelta\n",
        "import time\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "seed = 42\n",
        "random.seed = (seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "model.cuda()\n",
        "\n",
        "losses = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    print(\"Training:\")\n",
        "    start = time.time()\n",
        "    mean_loss = 0\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        \n",
        "        torch.cuda.empty_cache()\n",
        "        if (step + 1) % 100 == 0:\n",
        "            duration = timedelta(seconds=int(time.time() - start))\n",
        "            print('Batch {:>5,}  of  {:>5,}.    Time: {:}.'.format(step + 1, len(train_dataloader), duration))\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_attention_masks = batch[1].to(device)\n",
        "        b_targets = batch[2].to(device)\n",
        "        model.zero_grad()\n",
        "        \n",
        "        torch.cuda.empty_cache()\n",
        "        outputs = model(b_input_ids, attention_mask=b_attention_masks, labels = b_targets)\n",
        "        loss = outputs[0]\n",
        "        \n",
        "        mean_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        mean_loss = mean_loss / len(train_dataloader)\n",
        "    \n",
        "    losses.append(mean_loss)\n",
        "    print(\"Mean loss: \" , mean_loss)\n",
        "    print(\"Training epoch took:\" , timedelta(seconds=int(time.time() - start)))\n",
        "    \n",
        "    print()\n",
        "    print(\"Validation:\")\n",
        "    model.eval()\n",
        "    \n",
        "    start = time.time()\n",
        "    predictions = torch.Tensor().to(dtype=torch.int8)\n",
        "    \n",
        "    for batch in val_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_attention_masks = batch[1].to(device)\n",
        "        b_targets = batch[2].to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            outputs = model(b_input_ids, attention_mask=b_attention_masks, output_hidden_states=False, output_attentions=False, return_dict=True)\n",
        "        \n",
        "        predictions = torch.cat((predictions, outputs.logits.cpu().argmax(axis=1)))\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "    print(classification_report(val_y, predictions))\n",
        "    print(\"Validation took: {:}\".format(timedelta(seconds = int(time.time() - start))))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLLwLdw7N2qd"
      },
      "source": [
        "**Тестирование модели**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJu96aQoPpRX",
        "outputId": "08b26215-6c8c-45fd-d148-148ed26a4bcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.72      0.74      7189\n",
            "           1       0.82      0.88      0.85      6664\n",
            "           2       0.87      0.84      0.85      7078\n",
            "\n",
            "    accuracy                           0.81     20931\n",
            "   macro avg       0.81      0.82      0.81     20931\n",
            "weighted avg       0.81      0.81      0.81     20931\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Testing:\")\n",
        "model.eval()\n",
        "\n",
        "t0 = time.time()\n",
        "predictions = torch.Tensor().to(dtype=torch.int8)\n",
        "\n",
        "for batch in test_dataloader:\n",
        "\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_attention_masks = batch[1].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids, attention_mask=b_attention_masks, output_hidden_states=False, output_attentions=False, return_dict=True)\n",
        "\n",
        "    predictions = torch.cat((predictions, outputs.logits.cpu().argmax(axis=1)))\n",
        "\n",
        "print(classification_report(test_y ,predictions))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
