# Модели для оценки тональности
Для оценки разметки данных и оценки тональности использовались 4 модели. Первые 3 модели были обучены и протестированы на корпусе women_with_predict.
### Описание корпуса women_with_predict:

1. Объем корпуса: 90001
2. разметка с оценкой (2 - отрицательный, 0 - нейтральный, 1 - положительный)
3. Примерная длина документов (словами): 25

# Модели:
## №1 DeepPavlov/rubert-base-cased

### Описание модели
RuBERT (русский, 12-слойный, 768-размер скрытого слоя скрытый, 12-головной, 180М параметров) обучался на русскоязычной части Википедии и новостных данных. На этих обучающих данных мы построили словарь русских субтокенов и взяли мультиязычную версию BERT‑базы в качестве инициализации для RuBERT.

Результаты:

  Accuracy 0.68
  Precision 0.67, recall 0.68, F1 0.67
  Validation took: 0:00:53

## №2 DeepPavlov/rubert-base-cased-sentence
К данной модели был добавлен полносвязный слой.
### Описание модели
Sentence RuBERT (русский, 12-слойный, 768-размер скрытого слоя, 12-заголовочный, 180M параметров) — кодировщик предложений для русского языка на основе представления. Он инициализирован с помощью RuBERT и настроен на SNLI с гугл-переводом на русский и на русскоязычной части XNLI.

Результаты:

              precision    recall  f1-score   support

           0       0.66      0.69      0.67      5338
           1       0.92      0.86      0.89      5375
           2       0.75      0.75      0.75      5387
    accuracy                           0.77     16100

## №3 xlm-roberta-base

### Описание модели
Sentence RuBERT (русский, 12-слойный, 768-размер скрытого слоя, 12-заголовочный, 180M параметров) — кодировщик предложений для русского языка на основе представления. Он инициализирован с помощью RuBERT и настроен на SNLI с гугл-переводом на русский и на русскоязычной части XNLI.

Результаты:

              precision    recall  f1-score   support

           0       0.64      0.70      0.67      2730
           1       0.89      0.84      0.86      2729
           2       0.74      0.71      0.72      2591
    accuracy                           0.75      8050

## №4 Twitter/twhin-bert-base
Эта модель была обучена на предварительно сбалансированных корпусах: hotel, women, reviews, phone
### Описание корпусов
Отзывы отеля:
1. Объем корпуса: 6877 + 50329
2. отзывы на отель
3. бинарная 
4. Примерная длина документов (словами): 35

Телефоны
1. Объем корпуса: 458433
2. телефоны
3. балльная оценка
4. Примерная длина документов (словами): 100

Отзывы из магазина женской одежды:
1. Объем корпуса: 90001
2. отзывы из магазина женской одежды
3. разметка с оценкой
4. Примерная длина документов (словами): 20

### Описание модели
TwHIN-BERT — это новая многоязычная языковая модель твитов, которая обучается на 7 миллиардах твитов на более чем 100 различных языках. TwHIN-BERT отличается от предыдущих предварительно обученных языковых моделей тем, что обучается не только с помощью текстового самоконтроля (например, MLM), но и с социальной целью, основанной на богатом социальном взаимодействии в гетерогенной информационной сети Twitter.
280M параметров

Результаты:

              precision    recall  f1-score   support

           0       0.59      0.61      0.60      5587
           1       0.75      0.76      0.76      5567
           2       0.79      0.76      0.77      5589
    accuracy                           0.71     16743
