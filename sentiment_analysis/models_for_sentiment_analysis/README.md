# Модели для оценки тональности
## Для оценки разметки данных и оценки тональности использовались 4 модели. Первые 3 модели были обучены и протестированы на корпусе women_with_predict.
### Описание корпуса women_with_predict:

Формат csv
Объем корпуса 90001
Столбцы : review, sentiment (positive, negative, neutral)
Примерная длина отзыва 20 слов
Распределение признаков (0 - neutral, 1 - positive, 2 - negative)


# Модели:
## №1 DeepPavlov/rubert-base-cased

### Описание модели
RuBERT (русский, 12-слойный, 768-размер скрытого слоя скрытый, 12-головной, 180М параметров) обучался на русскоязычной части Википедии и новостных данных. На этих обучающих данных мы построили словарь русских субтокенов и взяли мультиязычную версию BERT‑базы в качестве инициализации для RuBERT.

### Результаты:

              precision    recall  f1-score   support

     Neutral       0.64      0.71      0.67      5000
    Positive       0.92      0.86      0.89      5427
    Negative       0.76      0.74      0.75      5218
    accuracy                           0.77     15645

## №2 DeepPavlov/rubert-base-cased-sentence
К данной модели был добавлен полносвязный слой.
### Описание модели
Sentence RuBERT (русский, 12-слойный, 768-размер скрытого слоя, 12-заголовочный, 180M параметров) — кодировщик предложений для русского языка на основе представления. Он инициализирован с помощью RuBERT и настроен на SNLI с гугл-переводом на русский и на русскоязычной части XNLI.

### Результаты:

              precision    recall  f1-score   support

     Neutral       0.66      0.69      0.67      5338
    Positive       0.92      0.86      0.89      5375
    Negative       0.75      0.75      0.75      5387
    accuracy                           0.77     16100

## №3 xlm-roberta-base

### Описание модели
Sentence RuBERT (русский, 12-слойный, 768-размер скрытого слоя, 12-заголовочный, 180M параметров) — кодировщик предложений для русского языка на основе представления. Он инициализирован с помощью RuBERT и настроен на SNLI с гугл-переводом на русский и на русскоязычной части XNLI.

### Результаты:

              precision    recall  f1-score   support

     Neutral       0.64      0.70      0.67      2730
    Positive       0.89      0.84      0.86      2729
    Negative       0.74      0.71      0.72      2591
    accuracy                           0.75      8050

## №4 Twitter/twhin-bert-base
Эта модель была обучена на предварительно сбалансированных корпусах: hotel, women, reviews, phone
### Описание корпусов

### Отзывы отеля:

    Формат xlsx (был приведен к csv)
    Объем корпуса 50328
    Столбцы: общая оценка, цена/качество, расположение, качество сна, номер, чистота, обслуживание, текст отзыва. Все оценки выставлены от 1 до 5. Нас интересовал         признак “общая оценка”. При приведении данных к единому виду, positive - 5, neutral -3,4, negative -1,2
    Среднее количество слов 
    Распределение признаков (0 - neutral, 1 - positive, 2 - negative)


### Отзывы на телефоны:

    Формат csv
    Объем корпуса 458433
    Столбцы: Review, Rating(1-5)
    При приведении данных к единому виду, positive - 5, neutral -3,4, negative -1,2
    Среднее количество слов 100
    Распределение признаков (0 - neutral, 1 - positive, 2 - negative)


### Отзывы из магазина женской одежды:

    Объем корпуса: 90001
    Предметная область: отзывы из магазина женской одежды
    Разделение лэйблов: разметка с оценкой
    Примерная длина документов (словами): 20

### !!! reviews:

    Формат csv
    Объем корпуса 119047
    Столбцы: Unnamed: 0,language,rating(1-5),category,combined_text
    при приведении данных к единому виду, positive - 5, neutral -3,4, negative -1,2
    Среднее количество слов 14
    Распределение признаков (0 - neutral, 1 - positive, 2 - negative)



### Описание модели
TwHIN-BERT — это новая многоязычная языковая модель твитов, которая обучается на 7 миллиардах твитов на более чем 100 различных языках. TwHIN-BERT отличается от предыдущих предварительно обученных языковых моделей тем, что обучается не только с помощью текстового самоконтроля (например, MLM), но и с социальной целью, основанной на богатом социальном взаимодействии в гетерогенной информационной сети Twitter.
280M параметров

## Проверка качества модели:

### На всех данных:

              precision    recall  f1-score   support

      Neutral       0.61      0.63      0.62      5614
     Positive       0.77      0.78      0.77      5539
     Negative       0.79      0.76      0.77      5595
     accuracy                           0.72     16748

    
### На корпусе hotel:

              precision    recall  f1-score   support

     Neutral       0.59      0.62      0.61      1378
    Positive       0.72      0.73      0.73      1426
    Negative       0.87      0.83      0.85      1383
    accuracy                           0.73      4187

### На корпусе phone:

              precision    recall  f1-score   support

     Neutral       0.57      0.59      0.58      1377
    Positive       0.68      0.71      0.70      1407
    Negative       0.78      0.73      0.76      1403
    accuracy                           0.68      4187


### На корпусе women:

              precision    recall  f1-score   support

     Neutral       0.64      0.66      0.65      1418
    Positive       0.90      0.85      0.87      1372
    Negative       0.72      0.73      0.72      1397
    accuracy                           0.75      4187

### На корпусе reviews:

              precision    recall  f1-score   support

     Neutral       0.64      0.63      0.64      1441
    Positive       0.79      0.82      0.81      1334
    Negative       0.79      0.76      0.77      1412
    accuracy                           0.74      4187
