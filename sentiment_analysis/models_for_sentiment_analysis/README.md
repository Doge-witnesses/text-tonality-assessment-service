# Модели для оценки тональности
Для оценки резметки данных и оценки тональности использовались 2 модели. Обе модели были обучены и протестированы на датасете women_with_predict.
### Описание датасета women_with_predict:

1. Объем корпуса: 90001
2. разметка с оценкой (2 - отрицательный, 0 - нейтральный, 1 - положительный)
3. Примерная длина документов (словами): 25

# Модели:
## №1 DeepPavlov/rubert-base-cased
Модель использовалась без добавления слоёв.
### Описание модели
RuBERT (русский, 12-слойный, 768-размер скрытого слоя скрытый, 12-головной, 180М параметров) обучался на русскоязычной части Википедии и новостных данных. На этих обучающих данных мы построили словарь русских субтокенов и взяли мультиязычную версию BERT‑базы в качестве инициализации для RuBERT.
## №2 DeepPavlov/rubert-base-cased-sentence
К данной модели был добавлен полносвязный слой.
### Описание модели
Sentence RuBERT (русский, 12-слойный, 768-размер скрытого слоя, 12-заголовочный, 180M параметров) — кодировщик предложений для русского языка на основе представления. Он инициализирован с помощью RuBERT и настроен на SNLI с гугл-переводом на русский и на русскоязычной части XNLI.
